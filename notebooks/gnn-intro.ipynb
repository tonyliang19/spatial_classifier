{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Payal Chandak, on 20 June 2020\n",
    "<br> <br>\n",
    "Graphs in the real world, such as social networks, chemical molecules and biological knowledge graphs, are rich with information that cannot be found in individual entities. A method for learning graph representations or node classification would be extremely valuable. Unfortunately, the modern deep learning toolbox is designed for grids (ie. images) and simple sequences (ie. text). CNNs and RNNs cannot generalize to graphs that have arbitrary size, complex topological structures and no fixed node ordering. Graph neural networks (GNN) provide a powerful tool to learn representations from any arbitrary graph structure by leveraging local network neighborhoods. This tutorial aims to (1) introduce the concept of graph neural networks, (2) discuss the quatitative motivation behind different GNN architectures and (3) implement these architectures using the PyTorch Geometric library. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.313897Z",
     "start_time": "2020-06-21T13:16:13.726701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chunq\\miniconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from IPython.lib.display import YouTubeVideo\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch_geometric.data import Data, GraphSAINTRandomWalkSampler\n",
    "from torch_geometric.datasets import Planetoid, Entities\n",
    "from torch_geometric.nn import GCNConv, RGCNConv, GATConv, SAGEConv, JumpingKnowledge, GINConv, DeepGraphInfomax\n",
    "\n",
    "torch.manual_seed(200620)\n",
    "np.random.seed(200620)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a Graph Neural Network? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph neural networks have a somewhat universal architecture where forward propagation uses a 'neighborhood aggregation' technique. The model iteratively produces new feature representations for a given node by aggregating the current feature representations of its adjacent nodes’ (ie. neighbors) and the node itself. Here, an iteration is parametrized by a layer of the neural network. This means that the computational graph of the neural network is defined by the neighborhood of each node. And, each layer in the graph neural network can be thought of as a step where each node aggregates messages from its neighboring nodes, as visualized by Microsoft in this [video](https://www.youtube.com/watch?v=cWIeTMklzNg):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.550554Z",
     "start_time": "2020-06-21T13:16:50.317019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"890\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/cWIeTMklzNg?start=70&end=460\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x12d14ad60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YouTubeVideo('cWIeTMklzNg', height=500, width=890, start=70, end=460)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a graph $\\mathcal{G} = (\\mathcal{V}, \\mathcal{E})$ described by an adjacency matrix $A$. The goal is to learn a function of node input features for node classification. The model takes as input a feature descriptions summarized by matrix $X$ which is $N \\times D$ ($N$: number of nodes, $D$: number of input features) and produces a node-level output $Z$ (a $N \\times C$ feature matrix, where $C$ is the number of classes per node). At the node level, each layer of the GNN is doing neighborhood aggregation to transform the node representation. At the graph level, every neural network layer can then be written as a non-linear function $f$: \n",
    "<br><br>$$H^{(l+1)}=f^{(l+1)}(H^{(l)},A)$$<br>\n",
    "with $H^{(0)}=X$ and $H^{(L)}=Z$, where L is the number of layers. Notice that each node started with an input vector of length $D$ and ended at a classification vector of length $C$, where $D$ need not equal $C$. This is possible because after doing neighborhood aggregation, $f$ applies a non-linear transformation to node representations using its parameters, a weight matrix $W$ and an activation $\\sigma$. The dimension of node representations will change from one layer to another when $W$ is not a square matrix. Note that each layer learns it's own parameters. The specific GNN architechtures then differ only in how $f(⋅,⋅)$ is chosen and parameterized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNN Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In recent years, many architectures of graph neural networks have been introduced. I will explore the quantitative motivations behind some of the most influential architectures in the field. I will also implement simple models using these architectures in PyTorch and evaluate them on the benchmark Cora dataset. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.700215Z",
     "start_time": "2020-06-21T13:16:50.560524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For this tutorial, we will use a standard citation dataset that is commonly used to benchmark GNN performance.\n",
      "The Cora dataset is a homogeneous, undirected graph where nodes are publications linked by citations.\n",
      "It contains:\n",
      "\t- 7 labels\n",
      "\t- 2708 nodes\n",
      "\t- 1208 training\n",
      "\t- 500 validation\n",
      "\t- 1000 testing\n"
     ]
    }
   ],
   "source": [
    "print('For this tutorial, we will use a standard citation dataset that is commonly used to benchmark GNN performance.')\n",
    "print('The Cora dataset is a homogeneous, undirected graph where nodes are publications linked by citations.')\n",
    "dataset = Planetoid(root='/tmp/Cora', name='Cora', split='full')\n",
    "print('It contains:')\n",
    "graph = dataset[0]\n",
    "print('\\t- {:d} labels'.format(dataset.num_classes))\n",
    "print('\\t- {:d} nodes'.format(graph.num_nodes))\n",
    "print('\\t- {:d} training'.format(graph.train_mask.sum().item()))\n",
    "print('\\t- {:d} validation'.format(graph.val_mask.sum().item()))\n",
    "print('\\t- {:d} testing'.format(graph.test_mask.sum().item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tools for Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.710903Z",
     "start_time": "2020-06-21T13:16:50.704353Z"
    }
   },
   "outputs": [],
   "source": [
    "class Hyperparameters():\n",
    "    def __init__(self):\n",
    "        self.num_node_features = None\n",
    "        self.num_classes = None\n",
    "        self.lr = 0.005\n",
    "        self.w_decay = 5e-4   \n",
    "        self.dropout = 0.3\n",
    "        self.epochs = 200                \n",
    "        self.cuda = True                \n",
    "        self.device  =  None    \n",
    "\n",
    "args = Hyperparameters()\n",
    "args.num_node_features = graph.num_node_features\n",
    "args.num_classes = dataset.num_classes\n",
    "args.cuda = args.cuda and torch.cuda.is_available() \n",
    "if args.cuda:\n",
    "    args.device = torch.device('cuda:0') \n",
    "else:\n",
    "    args.device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `LearnGraph`class can train an arbitrary GNN on an arbitrary graph for node classification. By default, binary cross entropy loss and adam optimizer are used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:16:50.729337Z",
     "start_time": "2020-06-21T13:16:50.714000Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class LearnGraph(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None:\n",
    "        # tracks training and validation loss over epochs\n",
    "        # can add early stopping mechanism by comparing losses\n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            \n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        # trains a single epoch (ie. one pass over the full graph) and updates the models parameters\n",
    "        # returns the loss\n",
    "        self.model.train()\n",
    "        labels = self.graph.y[self.graph.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float:\n",
    "        # returns the validation loss \n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        # returns the test accuracy \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]    \n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GCNConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GCNConv)** from Kipf and Welling: [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907) (ICLR 2017)\n",
    "Also see [this blog by Kipf](http://tkipf.github.io/graph-convolutional-networks/) \n",
    "<br> <br> \n",
    "The basic propagation rule is $$f: \\sigma\\left(A H^{(l)} W^{(l)}\\right)$$  \n",
    "According to the adjacency matrix, we sum the feature vectors of all neighboring nodes but not the node itself. We fix this by enforcing self-loops: $\\hat{A} = A + I$\n",
    "Another limitation is that $\\hat{A}$ is not normalized, so multiplication with $\\hat{A}$ will completely change the scale of the feature vectors. Let $\\hat{D}$ be the diagonal node degree matrix. Simple normalization involves using $\\hat{D}^{-1} \\hat{A} \\text{ instead of } \\hat{A}$. In practice, we do symmetric normalization such that the final propagation rule is <br><br> \n",
    "$$f: \\sigma\\left(\\hat{D}^{-\\frac{1}{2}} \\hat{A} \\hat{D}^{-\\frac{1}{2}} H^{(l)} W^{(l)}\\right)$$<br> \n",
    "For a given node $i$ feature vector, where $ N_{i}$ is its neighborhood and $c_{i j}$ is a normalization constant for the edge $(i, j)$, the update is:  <br> <br> \n",
    "$$h_{i}^{(l+1)}=\\sigma\\ \\left(\\ \\sum_{j \\ \\in \\ N_{i}} \\frac{1}{c_{i j}} \\ h_{j}^{(l)} \\ W^{(l)}\\ \\right)$$<br> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:17:04.817428Z",
     "start_time": "2020-06-21T13:16:50.735049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.4%\n"
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Graph Convolutional Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[RGCNConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.RGCNConv)** from Schlichtkrull *et al.*: [Modeling Relational Data with Graph Convolutional Networks](https://arxiv.org/abs/1703.06103) (ESWC 2018)\n",
    "<br> <br> \n",
    "'Knowledge' graphs have nodes connected by many different relationships. To capture many types of links in graphs, we can apply relation-specific transformations on incoming messages. For a specific node $i$, $\\mathcal{N}_{i}^{r}$ contains its neighbors connected by link $r$. $c_{i, r}$ is a normalization constant (such as $|\\mathcal{N}_{i}^{r}|$). \n",
    "<br> <br>  $$h_{i}^{(l+1)}=\\sigma\\left(\\ \\sum_{r \\ \\in \\ \\mathcal{R}} \\  \\sum_{j \\ \\in \\ \\mathcal{N}_{i}^{r}} \\frac{1}{c_{i, r}} \\ W_{r}^{(l)}  h_{j}^{(l)}+W_{0}^{(l)} h_{i}^{(l)}\\right)$$<br> \n",
    "The parameters of the network grow rapidly with the number of relations in the graph. We need regularlization to prevent overfitting on rare relations. Using basis decompostion, each $W_{r}^{(l)}$ is defined as a linear combination of basis vectors $V_{b}^{(l)} \\in \\mathbb{R}^{d^{(l+1)} \\times d^{(l)}}$, the space of $W_{r}^{(l)}$. Only the coefficients $a_{r b}^{(l)}$ depend on $r$. This method alleviates overfitting by creating weight sharing across frequent and rare relations. \n",
    "<br> <br> $$W_{r}^{(l)}=\\sum_{b=1}^{B} a_{r b}^{(l)} V_{b}^{(l)}$$<br> \n",
    "Since R-GCN is applied to heterogenous graphs, we will use the MUTAG graph instead of Cora. RGCN auto-generates unique embeddings as input features for nodes if no features are provided, as in MUTAG. Minor changes made to `LearnGraph`to accomodate MUTAG. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:18:06.863835Z",
     "start_time": "2020-06-21T13:17:04.821768Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 65>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index, edge_type)\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 65\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnMUTAG\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutag_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36mLearnMUTAG.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criterion: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "mutag_dataset = Entities(root='/tmp/MUTAG', name='MUTAG')\n",
    "mutag_graph = mutag_dataset[0]\n",
    "\n",
    "class LearnMUTAG(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None:\n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        self.model.train()\n",
    "        labels = self.graph.train_y\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.train_idx], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        # returns the test accuracy \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.test_y\n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_idx].eq(labels).sum().item() )\n",
    "        acc = correct / len(self.graph.test_idx)\n",
    "        return acc\n",
    "    \n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = RGCNConv(mutag_graph.num_nodes, 16, mutag_dataset.num_relations, num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, mutag_dataset.num_classes, mutag_dataset.num_relations, num_bases=30)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index, edge_type = graph.x, graph.edge_index, graph.edge_type\n",
    "        x = self.conv1(x, edge_index, edge_type)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return x\n",
    "\n",
    "learner = LearnMUTAG(model=GNN(), graph=mutag_graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Attention Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GATConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GATConv)** from Veličković *et al.*: [Graph Attention Networks](https://arxiv.org/abs/1710.10903) (ICLR 2018)\n",
    "<br> <br> \n",
    "GATConv is inspired by the use of self-attention (Google transformer) which has achieved SOTA performance in NLP. The idea is that nodes can 'attend' over their neighbors and select the direction from which they recieve information. For a single layer, where nodes go from $F$ to $F^{\\prime}$ features, the following steps are applied: \n",
    "\n",
    "1. Linear transformation of input features using a weight matrix, $\\mathbf{W} \\in \\mathbb{R}^{F^{\\prime} \\times F}$\n",
    "\n",
    "2. Compute attention coefficients $e_{i j} \\in \\mathbb{R}$ for each node pair $(i, j)$ using a shared attention mechanism $a$. Here this mechanism is a single-layer feedforward network network with a the parameter vector, $\\overrightarrow{\\mathbf{a}} \\in \\mathbb{R}^{2 F^{\\prime}}$\n",
    "<br> <br>$$e_{i j}=a\\left(\\mathbf{W} \\vec{h}_{i}, \\mathbf{W} \\vec{h}_{j}\\right) = \\text{LeakyReLU}\\left(\\overrightarrow{\\mathbf{a}}^{T}\\left[\\mathbf{W} \\vec{h}_{i} \\| \\mathbf{W} \\vec{h}_{j}\\right]\\right)$$ <br>\n",
    "\n",
    "3. Normalize attention coefficients across nodes: $\\alpha_{i j}=\\operatorname{softmax}_{j}\\left(e_{i j}\\right)$ \n",
    "\n",
    "4. Compute output features as a linear combination of input features corresponding to their normalized attention coefficients \n",
    "<br> <br> $$\\vec{h}_{i}^{\\prime}=\\sigma\\left(\\sum_{j \\in \\mathcal{N}_{i}} \\alpha_{i j} \\mathbf{W} \\vec{h}_{j}\\right)$$ <br>\n",
    "5. This process can be stabilized using multi-head attention, which concatenates/averages multiple indepedently computed output features from independent attention layers <br> <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:18:25.584282Z",
     "start_time": "2020-06-21T13:18:06.869480Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 18\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mLearnGraph.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criterion: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GATConv(args.num_node_features, 8, heads=8)\n",
    "        self.conv2 = GATConv(64, args.num_classes, heads=1)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAGE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[SAGEConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.SAGEConv)** from Hamilton *et al.*: [Inductive Representation Learning on Large Graphs](https://arxiv.org/abs/1706.02216) (NIPS 2017)\n",
    "<br> <br> \n",
    "GraphSAGE generalizes GCN to use trainable aggregation functions beyond simple convolutions. For a given layer $(l+1)$, at each node $i$, the embeddings $h_{j}^{(l)}$ for all nodes $j$ in its neighborhood $\\mathcal{N}(i)$ are combined into a single vector $h^{(l+1)}_{\\mathcal{N}(i)}$ using an aggregation function. Aggregating the neighborhood separately from the node itself implictly adds skip connections across layers.\n",
    "<br> <br> $$\\mathbf{h}_{\\mathcal{N}(i)}^{(l+1)} = \\operatorname{AGGREGATE}_{(l+1)}\\left(\\left\\{\\mathbf{h}_{j}^{(l)}, \\forall j \\in \\mathcal{N}(i)\\right\\}\\right)$$  <br>\n",
    "Aggregation functions can include mean (~traditional GCN), LSTM and Pooling. In max pooling, each neighbor vector is fed through a single-layer neural network and then an elementwise max-pooling operation is applied. Max pooling implicitly selects the important nodes, much like Graph Attention Networks.\n",
    "<br> <br> $$\\mathrm{AGGREGATE}_{(l+1)}^{\\mathrm{pool}}=\\max \\left(\\left\\{\\sigma\\left(\\mathbf{W}_{\\mathrm{pool}} \\ \\mathbf{h}_{j}^{(l+1)}+\\mathbf{b}\\right), \\forall j \\in \\mathcal{N}(i)\\right\\}\\right)$$ <br>\n",
    "The final step is to concatenate the node's current representation $h^{(l)}_{i}$ with the aggregated neighborhood vector $h^{(l+1)}_{\\mathcal{N}(i)}$. This concatenated vector is fed through a single-layer neural network to calculate the output representation $h^{(l+1)}_{i}$\n",
    "<br> <br> $$\\mathbf{h}_{i}^{(l+1)} = \\sigma \\left(W_{(l+1)} \\left[\\ h^{(l)}_{i} \\  \\| \\  h^{(l+1)}_{\\mathcal{N}(i)}\\ \\right] \\right)$$ <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:19:51.863950Z",
     "start_time": "2020-06-21T13:18:25.600366Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[0;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 21\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mLearnGraph.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criterion: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(args.num_node_features, 64, normalize=True)\n",
    "        self.conv1.aggr = 'max'\n",
    "        self.conv2 = SAGEConv(64, args.num_classes,  normalize=True)\n",
    "        self.conv2.aggr = 'max'\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "        print()\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jumping Knowledge Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Jumping Knowledge](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.JumpingKnowledge)** from Xu *et al.*: [Representation Learning on Graphs with Jumping Knowledge Networks](https://arxiv.org/abs/1806.03536) (ICML 2018)\n",
    "<br> <br>\n",
    "Many aggregation based models achieve best performance with 2 layer networks. After that, performance degrades despite theoretically greater access to information and even after adding residual connections. In biological networks, the majority of the nodes have few connections, whereas some nodes are hubs. In the same graph, the same number of GNN layers an lead to very different effects for different nodes. \n",
    "<br> <br>\n",
    "Unlike GAT or GraphSAGE which select the direction of expansion, Jumping Knowledge operates on the locality of expansion. This model proposes two architectural changes – jump connections and a subsequent selective but adaptive aggregation mechanism. As in common neighborhood aggregation networks, each layer increases the size of the influence distribution by aggregating neighborhoods from the previous layer. In the last JK layer, for each node, we select from all of those intermediate representations. If this is done independently for each node, then the model can adapt the effective neighborhood size for each node as needed, resulting in exactly the desired adaptivity. The layer aggregation mechanisms can include concatenation, max pooling, and lstm attention. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:20:32.835990Z",
     "start_time": "2020-06-21T13:19:51.866615Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(x)\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 27\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mLearnGraph.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criterion: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.convx= GCNConv(64, 64)\n",
    "        self.jk = JumpingKnowledge(mode='max')\n",
    "        self.final = nn.Linear(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        xs = []\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        xs.append(x)\n",
    "        for _ in range(5): \n",
    "            x = self.convx(x, edge_index)\n",
    "            x = self.transition(x)\n",
    "            xs.append(x)\n",
    "        x = self.jk(xs)\n",
    "        x = self.final(x)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Isomorphism Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GINConv](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.conv.GINConv)** from Xu *et al.*: [How Powerful are Graph Neural Networks?](https://arxiv.org/abs/1810.00826) (ICLR 2019)\n",
    "<br> <br>\n",
    "This work aimed to increase the expressive power of GNNs. The Weisfeiler-Lehman (WL) test for graph isomorphism uses injective node aggregation to distinguish graphs from each other. They show that GNNs can be as powerful as the WL test in distinguishing graph structures if the GNN’s aggregation scheme is highly expressive and can model injective (one-one) functions. A nodes neighbors are defined as a multiset, i.e., a set with possibly repeating elements. Sum aggregators can represent injective (and universal) functions over multisets. On the other hand, mean or max aggregators (used in GraphSAGE or GCN) are not injective multiset functions. The Graph Isomorphism Network uses a multi-layer perceptron to do neighborhood aggregation. Note that this argument holds under their key assumption that \"node input features are from a countable universe\" which is a very simplistic view of input features. \n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:01.715535Z",
     "start_time": "2020-06-21T13:20:32.842442Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 29>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 29\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36mLearnGraph.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m criterion: \n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(args.num_node_features, 256), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(256, 64), \n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(64, 16), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, args.num_classes), \n",
    "        )\n",
    "        self.conv2= GINConv(self.mlp2)\n",
    "        \n",
    "        \n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "        \n",
    "learner = LearnGraph(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Graph Infomax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Deep Graph Infomax](https://pytorch-geometric.readthedocs.io/en/latest/modules/nn.html#torch_geometric.nn.models.DeepGraphInfomax)** from Veličković *et al.*: [Deep Graph Infomax](https://arxiv.org/abs/1809.10341) (ICLR 2019)\n",
    "<br> <br>\n",
    "Unsupervised embeddings have traditionally been trained with random-walk objectives, which can over-emphasize proximity information at the expense of structural information. Since encoders already enforce an inductive bias that neighboring nodes have similar representations, it is unclear whether random-walk objectives actually provide any useful signal. Deep graph infomax is an alternative objective for unsupervised graph learning that is based upon mutual information. \n",
    "<br> <br>\n",
    "The DGI objective seeks to maximize local mutual information by obtaining obtain node (i.e., local) representations that capture the global information content of the entire graph. As all of the derived patch representations are driven to preserve mutual information with the global graph summary, this allows for discovering and preserving similarities on the patch-level. This is useful because distant nodes with similar structural roles are known to be a strong predictor for many node classification tasks.\n",
    "<br> <br>\n",
    "The DGI model is defined by an encoder $\\mathcal{E}$, discriminator $\\mathcal{D}$, readout function $\\mathcal{R}$ and corruption function $\\mathcal{C}$. The GNN encoder outputs node representations $h_{i}$. The readout function gives a summary vector, $\\vec{s}$, which is the global graph representation. The discriminator takes the graph summary $s$ and a node $h_{i}$ and assigns a co-occurence probablity $\\mathcal{D}(h_{i}, s)$ to the pair. For negative samples, the graph structured is randomly changed using $\\mathcal{C}$, and the same process is repeated. The objective is structured in binary cross entropy form: \n",
    "<br> <br>$$\\mathcal{L}=\\frac{1}{N+M}\\left(\\sum_{i=1}^{N} \\mathbb{E}_{(\\mathbf{X}, \\mathbf{A})}\\left[\\log \\mathcal{D}\\left(\\vec{h}_{i}, \\vec{s}\\right)\\right]+\\sum_{j=1}^{M} \\mathbb{E}_{(\\widetilde{\\mathbf{X}}, \\widetilde{\\mathbf{A}})}\\left[\\log \\left(1-\\mathcal{D}\\left(\\overrightarrow{\\widetilde{h}_{j}}, \\vec{s}\\right)\\right)\\right]\\right)$$ <br>\n",
    "For supervised learning, we can incorporate the DGI objective in an intermediate, hidden layer in conjunction with the traditional BCE loss at the final layer.<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:22.502344Z",
     "start_time": "2020-06-21T13:22:01.717780Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 99>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index): \n\u001b[0;32m     96\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv(x, edge_index)\n\u001b[1;32m---> 99\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnDeepGraphInfomax\u001b[49m\u001b[43m(\u001b[49m\u001b[43menc_dgi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEncoder_DGI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEncoder_CLS\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36mLearnDeepGraphInfomax.__init__\u001b[1;34m(self, graph, enc_dgi, enc_cls, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, enc_dgi, enc_cls, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m): \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdgi_model \u001b[38;5;241m=\u001b[39m DeepGraphInfomax(enc_dgi\u001b[38;5;241m.\u001b[39mhidden_ch, enc_dgi, enc_dgi\u001b[38;5;241m.\u001b[39msummary, enc_dgi\u001b[38;5;241m.\u001b[39mcorruption)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdgi_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdgi_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class LearnDeepGraphInfomax(): \n",
    "    \n",
    "    def __init__(self, graph, enc_dgi, enc_cls, args, criterion=None): \n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        \n",
    "        self.dgi_model = DeepGraphInfomax(enc_dgi.hidden_ch, enc_dgi, enc_dgi.summary, enc_dgi.corruption)\n",
    "        self.dgi_model = self.dgi_model.to(self.args.device)\n",
    "        \n",
    "        self.cls_model = enc_cls.to(self.args.device)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        parameters = [*self.dgi_model.parameters()] + [*self.cls_model.parameters()]\n",
    "        self.optim = torch.optim.Adam(parameters, lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False\n",
    "        \n",
    "    def learn(self) -> None: \n",
    "        for epoch in range(self.args.epochs): \n",
    "            if self.train_complete: return\n",
    "            \n",
    "            tl = self.train_epoch()\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True   \n",
    "        \n",
    "    def train_epoch(self) -> float:\n",
    "        self.dgi_model.train()\n",
    "        self.cls_model.train()\n",
    "        labels = self.graph.y[self.graph.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(x=self.graph.x, edge_index=self.graph.edge_index)\n",
    "        output = self.cls_model.forward(pos_z, self.graph.edge_index)\n",
    "        loss = self.dgi_model.loss(pos_z, neg_z, summary) + self.criterion(output[self.graph.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float: \n",
    "        self.dgi_model.eval()\n",
    "        self.cls_model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(self.graph.x, self.graph.edge_index)\n",
    "        output = self.cls_model.forward(pos_z, self.graph.edge_index)\n",
    "        loss = self.dgi_model.loss(pos_z, neg_z, summary) + self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.dgi_model.eval()\n",
    "        self.cls_model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]   \n",
    "        pos_z, neg_z, summary = self.dgi_model.forward(self.graph.x, self.graph.edge_index)\n",
    "        _, pred = self.cls_model.forward(pos_z, self.graph.edge_index).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "\n",
    "\n",
    "class Encoder_DGI(torch.nn.Module):\n",
    "    def __init__(self, hidden_ch=64): \n",
    "        super(Encoder_DGI, self).__init__()\n",
    "        self.hidden_ch = hidden_ch\n",
    "        self.conv = GCNConv(args.num_node_features, hidden_ch)\n",
    "        self.activation = nn.PReLU()\n",
    "        \n",
    "    def corruption(self, x, edge_index): \n",
    "        # corrupted features are obtained by row-wise shuffling of the original features \n",
    "        # corrupted graph consists of the same nodes but located in different places \n",
    "        return x[torch.randperm(x.size(0))], edge_index\n",
    "        \n",
    "    def summary(self, z, *args, **kwargs): \n",
    "        return torch.sigmoid(z.mean(dim=0))\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "        x = self.conv(x, edge_index)\n",
    "        x = self.activation(x)\n",
    "        return x \n",
    "\n",
    "\n",
    "class Encoder_CLS(torch.nn.Module):\n",
    "    def __init__(self, hidden_ch=64): \n",
    "        super(Encoder_CLS, self).__init__()\n",
    "        self.conv = GCNConv(hidden_ch, args.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index): \n",
    "        return self.conv(x, edge_index)\n",
    "\n",
    "\n",
    "learner = LearnDeepGraphInfomax(enc_dgi=Encoder_DGI(), enc_cls=Encoder_CLS(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GraphSAINT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[GraphSAINT](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.GraphSAINTSampler)** from Zeng *et al.*: [GraphSAINT: Graph Sampling Based Inductive Learning Method](https://arxiv.org/abs/1907.04931) (ICLR 2020)\n",
    "<br> <br> \n",
    "As the GNN becomes deeper, training time can grow exponentially due to \"neighbor explosion\". GraphSAINT samples the training graph first and then builds a full GNN on the subgraph. Intuitively, nodes of higher influence on each other should have higher probability to form a subgraph. This enables the sampled nodes to “support” each other without going outside the minibatch. Unfortunately, such strategy results in non-identical node sampling probability, and introduces bias in the minibatch estimator. GraphSAINT employs normalization techniques so that the feature learning does not give preference to nodes more frequently sampled. The GraphSAINT sampler can be applied to any graph irrespective of the GNN being trained on that graph.\n",
    "<br> <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-21T13:22:27.784728Z",
     "start_time": "2020-06-21T13:22:22.504838Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 78>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x, edge_index)\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[1;32m---> 78\u001b[0m learner \u001b[38;5;241m=\u001b[39m \u001b[43mLearnGraphSAINT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mGNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m acc \u001b[38;5;241m=\u001b[39m learner\u001b[38;5;241m.\u001b[39mtest()\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{:.1%}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(acc))\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mLearnGraphSAINT.__init__\u001b[1;34m(self, graph, model, args, criterion)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, graph, model, args, criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m args\n\u001b[1;32m----> 5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader \u001b[38;5;241m=\u001b[39m  GraphSAINTRandomWalkSampler(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgraph, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, walk_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, num_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:251\u001b[0m, in \u001b[0;36mBaseData.to\u001b[1;34m(self, device, non_blocking, *args)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:234\u001b[0m, in \u001b[0;36mBaseData.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstores:\n\u001b[1;32m--> 234\u001b[0m     \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:159\u001b[0m, in \u001b[0;36mBaseStorage.apply\u001b[1;34m(self, func, *args)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the function :obj:`func`, either to all attributes or only\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;124;03mthe ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m \u001b[43mrecursive_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\storage.py:510\u001b[0m, in \u001b[0;36mrecursive_apply\u001b[1;34m(data, func)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_apply\u001b[39m(data: Any, func: Callable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Tensor):\n\u001b[1;32m--> 510\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mPackedSequence):\n\u001b[0;32m    512\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(data)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch\\lib\\site-packages\\torch_geometric\\data\\data.py:252\u001b[0m, in \u001b[0;36mBaseData.to.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto\u001b[39m(\u001b[38;5;28mself\u001b[39m, device: Union[\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mstr\u001b[39m], \u001b[38;5;241m*\u001b[39margs: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m    248\u001b[0m        non_blocking: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs tensor device conversion, either for all attributes or\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03m    only the ones given in :obj:`*args`.\"\"\"\u001b[39;00m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m--> 252\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39margs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: invalid device ordinal\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "class LearnGraphSAINT(): \n",
    "    \n",
    "    def __init__(self, graph, model, args, criterion=None):\n",
    "        self.args = args\n",
    "        self.graph = graph.to(self.args.device)\n",
    "        self.model = model.to(self.args.device)\n",
    "        \n",
    "        self.loader =  GraphSAINTRandomWalkSampler(self.graph, batch_size=100, walk_length=2, num_steps=self.args.epochs)\n",
    "        \n",
    "        if not criterion: \n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "        self.criterion = criterion\n",
    "        \n",
    "        self.optim = torch.optim.Adam(self.model.parameters(), lr=self.args.lr, weight_decay=self.args.w_decay)\n",
    "        \n",
    "        self.train_loss = []\n",
    "        self.val_loss = []\n",
    "        self.train_complete = False \n",
    "        \n",
    "    def learn(self) -> None: \n",
    "        \n",
    "        for epoch, batch in enumerate(self.loader): \n",
    "            if self.train_complete: return\n",
    "        \n",
    "            tl = self.train_batch(batch)\n",
    "            self.train_loss.append(tl)\n",
    "            \n",
    "            vl = self.val()\n",
    "            self.val_loss.append(vl)\n",
    "                \n",
    "        self.train_complete = True\n",
    "        \n",
    "    def train_batch(self, batch) -> float:\n",
    "        self.model.train()\n",
    "        labels = batch.y[batch.train_mask]\n",
    "        self.optim.zero_grad()\n",
    "        output = self.model.forward(batch) \n",
    "        loss = self.criterion(output[batch.train_mask], labels)\n",
    "        loss.backward()\n",
    "        self.optim.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def val(self) -> float: \n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.val_mask]\n",
    "        output = self.model.forward(self.graph) \n",
    "        loss = self.criterion(output[self.graph.val_mask], labels)\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def test(self) -> float: \n",
    "        if not self.train_complete: \n",
    "            self.learn()\n",
    "        self.model.eval()\n",
    "        labels = self.graph.y[self.graph.test_mask]    \n",
    "        _, pred = self.model.forward(self.graph).max(dim=1)\n",
    "        correct = float ( pred[self.graph.test_mask].eq(labels).sum().item() )\n",
    "        acc = correct / self.graph.test_mask.sum().item()\n",
    "        return acc\n",
    "\n",
    "\n",
    "class GNN(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(GNN, self).__init__()\n",
    "        self.conv1 = GCNConv(args.num_node_features, 64)\n",
    "        self.conv2 = GCNConv(64, args.num_classes)\n",
    "        self.transition = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=args.dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, graph): \n",
    "        x, edge_index = graph.x, graph.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.transition(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "learner = LearnGraphSAINT(model=GNN(), graph=graph, args=args)\n",
    "acc = learner.test()\n",
    "print('Accuracy: {:.1%}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More...\n",
    "* PyTorch Geometric [GitHub](https://github.com/rusty1s/pytorch_geometric) – even more architectures and examples\n",
    "* Customizing GNNs – using the [Message Passing base class](https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html) in PyTorch Geometric\n",
    "* [Deep Graph Library](https://www.dgl.ai) – an alternative to PyTorch Geometric"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "344.0625px",
    "left": "941.9701538085938px",
    "top": "72.25000762939453px",
    "width": "224.15760803222656px"
   },
   "toc_section_display": false,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
